{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "import time\n",
    "\n",
    "data_path = 'C:/Users/SpiffyApple/Documents/USC/OwnResearch/marketShare'\n",
    "dbname = 'LAcounty_assessor.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "I compute Herfindalh-Hirshmann Indexes (HHIs) for LA County at the block, block group, and tract level. \n",
    "\n",
    "Land-use codes are officially detailed [here](https://www.titleadvantage.com/mdocs/LA%20County%20Use%20Codes%20nm.pdf) but I am not about to transcribe manually a pdf file so instead, I use the html table compiled by [dts.edatatrace](http://dts.edatatrace.com/dts3/content/doc/whelp/mergedProjects/dts2tt/mergedProjects/dts2ttcs/land_use_la.htm).\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1) I [transfer](#load-assessor-data-and-dump-to-sqlite) the assessor data to an sqlite databse for ease of use. \n",
    "\n",
    "2) I [save](#dump-to-geocode) a subset (AIN and lat/lon fields) of the owner data to a csv, make it into a qGIS file.\n",
    "\n",
    "3) I perform a [spatial join](#join-data-to-census-blocks) of the properties to 2010 Census blocks \n",
    "\n",
    "4) I compute [ownership shares](#hirschmann-herfindalh-indexes) and Herfindahl-Hirschmann indexes at the City, Census tract, and Census block level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns out, the\n",
    "#landuse = pd.read_html('http://dts.edatatrace.com/dts3/content/doc/whelp/mergedProjects/dts2tt/mergedProjects/dts2ttcs/land_use_la.htm')[0]\n",
    "#landuse.columns = landuse.iloc[0]\n",
    "#landuse = landuse.iloc[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load assessor data and dump to sqlite\n",
    "\n",
    "This saves space and enables me to query the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create convenience functions\n",
    "def getTableNames(dbfile, lookfor=\"'table'\"):\n",
    "    #open connection\n",
    "    conn =  sqlite3.connect(\"/\".join([data_path, dbfile]))\n",
    "    c = conn.cursor()\n",
    "\n",
    "    #fetch names\n",
    "    res = c.execute(\"SELECT name FROM sqlite_master WHERE type=%s;\" %lookfor)\n",
    "    print(res.fetchall())\n",
    "    \n",
    "    #close connection\n",
    "    conn.close()   \n",
    "\n",
    "def queryDB(query, dbfile):\n",
    "    conn =  sqlite3.connect(\"/\".join([data_path, dbfile]))\n",
    "    print(\"Connection opened to [%s]\" %dbfile)\n",
    "    start_time = time.time()\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    print(\"\\tsize of file read in:\", df.shape)\n",
    "    print(\"\\tquery took: %.2fseconds\" %(time.time()-start_time))\n",
    "    conn.close()\n",
    "    print(\"\\tConnection closed\")\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on chunk num: 0\n",
      "----------------------------------------\n",
      "Working on chunk num: 1\n",
      "----------------------------------------\n",
      "Working on chunk num: 2\n",
      "----------------------------------------\n",
      "Working on chunk num: 3\n",
      "----------------------------------------\n",
      "Working on chunk num: 4\n",
      "----------------------------------------\n",
      "Total number of observations: 2406966\n",
      "Done. This took 160.65seconds\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Working on chunk num: 0\n",
      "----------------------------------------\n",
      "Working on chunk num: 1\n",
      "----------------------------------------\n",
      "Working on chunk num: 2\n",
      "----------------------------------------\n",
      "Working on chunk num: 3\n",
      "----------------------------------------\n",
      "Working on chunk num: 4\n",
      "----------------------------------------\n",
      "Working on chunk num: 5\n",
      "----------------------------------------\n",
      "Total number of observations: 2679323\n",
      "Done. This took 48.17seconds\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## open connection to SQlite database\n",
    "conn =  sqlite3.connect(\"/\".join([data_path, dbname]))\n",
    "\n",
    "## create iteratable csv reader\n",
    "chunksize = 50e4\n",
    "reader = pd.read_csv(\"/\".join([data_path, 'assessor-owners-20190502.csv']),chunksize=chunksize, low_memory=False)\n",
    "\n",
    "observationCounter = 0\n",
    "start_time = time.time() #start timer\n",
    "tableName = 'assessor'\n",
    "for i,chunk in enumerate(reader):\n",
    "    print(\"Working on chunk num: %d\" %i)\n",
    "    observationCounter+=chunk.shape[0]\n",
    "    #print(\"\\tNum of rows in chunk: %d\" %chunk.shape[0])\n",
    "    ## fix a few data formats\n",
    "    chunk.loc[:,'AIN'] = chunk.AIN.astype('float')\n",
    "    chunk.loc[:,'Units1'] = chunk.Units1.replace(\"None\",0).astype(np.int)\n",
    "    chunk.loc[:,'UseCode_2'] = chunk.UseCode_2.astype(np.int)\n",
    "    chunk.loc[:,'MailZip'] = chunk.MailZip.str.replace(\"-|\\s+\",'').replace(\"\",0).astype(np.int)\n",
    "    \n",
    "    ## dump to database\n",
    "    chunk.to_sql(tableName,conn, if_exists='append', index=False)\n",
    "    print(\"--\"*20)\n",
    "    \n",
    "print(\"Total number of observations: %d\" %observationCounter)    \n",
    "print(\"Done. This took %.2fseconds\" %(time.time()-start_time))\n",
    "print(\"--\"*50)\n",
    "\n",
    "## repeat above for property history\n",
    "reader = pd.read_csv(\"/\".join([data_path, 'assessor-owner-change-2009-2019.csv']),chunksize=chunksize, iterator=True, low_memory=False)\n",
    "tableName = 'history'\n",
    "\n",
    "observationCounter = 0\n",
    "start_time = time.time() #start timer\n",
    "for i,chunk in enumerate(reader):\n",
    "    print(\"Working on chunk num: %d\" %i)\n",
    "    #print(\"\\tNum of rows in chunk: %d\" %chunk.shape[0])\n",
    "    observationCounter+=chunk.shape[0]\n",
    "    chunk.to_sql(tableName,conn, if_exists='append', index=False)\n",
    "    print(\"--\"*20)\n",
    "    \n",
    "print(\"Total number of observations: %d\" %observationCounter)     \n",
    "print(\"Done. This took %.2fseconds\" %(time.time()-start_time))  \n",
    "print(\"--\"*50)\n",
    "\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create indexes for faster queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing query 0\n",
      "\tthis took 10.96seconds\n",
      "executing query 1\n",
      "\tthis took 7.19seconds\n",
      "executing query 2\n",
      "\tthis took 9.41seconds\n",
      "executing query 3\n",
      "\tthis took 5.64seconds\n"
     ]
    }
   ],
   "source": [
    "## creating indexes\n",
    "conn =  sqlite3.connect(\"/\".join([data_path, dbname]))\n",
    "c = conn.cursor()\n",
    "ques =  [\"CREATE INDEX usetype ON assessor (UseType);\",\n",
    "    \"CREATE INDEX city ON assessor (SitusCity);\",\n",
    "    \"CREATE INDEX value ON assessor (Roll_ImpValue);\",\n",
    "    \"CREATE INDEX units ON assessor (Units1);\",\n",
    "    \"CREATE INDEX ain on assessor (AIN)\"]\n",
    "\n",
    "for i,q in enumerate(ques):\n",
    "    start_time = time.time()\n",
    "    print(\"executing query %d\" %i)\n",
    "    c.execute(q)\n",
    "    print(\"\\tthis took %.2fseconds\" %(time.time()-start_time))\n",
    "    conn.commit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get table names    \n",
    "getTableNames(dbname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump data to geocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = queryDB(\"SELECT AIN, CENTER_LAT, CENTER_LON FROM assessor WHERE UseType = 'Residential'\", dbname)\n",
    "df.to_csv(\"/\".join([data_path, 'toGeocode_lac.csv']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join data to Census Blocks\n",
    "\n",
    "I used the csv above to create a shapefile in qGIS, now I load that resulting shapefile and the [TIGER shapefile](https://www.census.gov/cgi-bin/geo/shapefiles/index.php) to attach Census blocks to property locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SpiffyApple\\Anaconda3\\lib\\site-packages\\geopandas\\tools\\sjoin.py:44: UserWarning: CRS of frames being joined does not match!\n",
      "  warn('CRS of frames being joined does not match!')\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from geopandas.tools import sjoin\n",
    "print(\"Modules imported\")\n",
    "\n",
    "point = gpd.GeoDataFrame.from_file(\"/\".join([data_path,'toGeocode_lac.shp'])) # or geojson etc\n",
    "point.drop('field_1',axis=1,inplace=True)\n",
    "poly = gpd.GeoDataFrame.from_file(\"/\".join([data_path,'tl_2010_06037_tabblock10.shp']))\n",
    "print(\"Shapefiles loaded\")\n",
    "\n",
    "print(\"Performing spatial join...\")\n",
    "start_time = time.time()\n",
    "pointInPolys = sjoin(point, poly, how='left')\n",
    "print(\"\\tSpatial join done. It took: %.2fseconds\" %(time.time()-start_time))\n",
    "\n",
    "pointInPolys.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save subset to SQLite\n",
    "pointInPolys[['AIN','STATEFP10', 'COUNTYFP10', 'TRACTCE10', 'BLOCKCE10', 'GEOID10']].to_sql('blocks',conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a geocoded view in the sqlite database of the assessor table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. This query took 116.96\n"
     ]
    }
   ],
   "source": [
    "conn =  sqlite3.connect(\"/\".join([data_path, dbname]))\n",
    "c = conn.cursor()\n",
    "\n",
    "start_time = time.time()\n",
    "c.execute(\"CREATE TABLE geoAssessor AS SELECT * FROM assessor INNER JOIN blocks ON assessor.AIN = blocks.AIN;\")\n",
    "print(\"Done. This query took %.2f\" %(time.time()-start_time))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hirschmann Herfindalh Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection opened to [LAcounty_assessor.db]\n",
      "\tsize of file read in: (2152993, 12)\n",
      "\tquery took: 23.02seconds\n",
      "\tConnection closed\n"
     ]
    }
   ],
   "source": [
    "## dont need all of the columns so I only read in the ones that will be required for computing shares and indexes\n",
    "cols = ['AIN','OwnerName','MailAddress', 'MailCity', 'MailZip','Units1','COUNTYFP10','UseCode_2','TRACTCE10', 'BLOCKCE10',\n",
    "       'GEOID10','SitusCity']\n",
    "df = queryDB(\"SELECT %s FROM geoAssessor;\" %(\",\".join(cols)), dbname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIN            object\n",
       "OwnerName      object\n",
       "MailAddress    object\n",
       "MailCity       object\n",
       "MailZip        object\n",
       "Units1         object\n",
       "COUNTYFP10     object\n",
       "UseCode_2      object\n",
       "TRACTCE10      object\n",
       "BLOCKCE10      object\n",
       "GEOID10        object\n",
       "SitusCity      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix a few column types. For example, units should NOT be object. Not Should AIN?\n",
    "df.loc[:,'AIN'] = df.AIN.astype('float')\n",
    "df.loc[:,'Units1'] = df.Units1.replace(\"None\",0).astype(np.int)\n",
    "df.loc[:,'UseCode_2'] = df.UseCode_2.astype(np.int)\n",
    "df.loc[:,'MailZip'] = df.MailZip.str.replace(\"-|\\s+\",'').replace(\"\",0).astype(np.int)\n",
    "\n",
    "df.loc[:,'SitusCity'] = df.SitusCity.str.replace(\" CA|/CA|-CA|\\.|\\d+|\\([\\w\\s]+\\)\",'').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of residential properties: 2152993\n",
      "Number of units in LA County: 3078263\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of residential properties: %d\" %df.AIN.shape[0])\n",
    "print(\"Number of units in LA County: %d\" %df.Units1.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-modular or non-mobile residential properties: 2149606\n",
      "Number of non-modular or non-mobile in LA County: 3040543\n"
     ]
    }
   ],
   "source": [
    "## remove units with use code >5\n",
    "df = df[df.UseCode_2<=5]\n",
    "print(\"Number of non-modular or non-mobile residential properties: %d\" %df.AIN.shape[0])\n",
    "print(\"Number of non-modular or non-mobile in LA County: %d\" %df.Units1.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of residential properties with at least 1 unit: 2034395\n",
      "Number of residential units in LA County with at least 1 unit: 3040543\n"
     ]
    }
   ],
   "source": [
    "## drop observations that have 0 units\n",
    "df.loc[df.Units1==0, 'UseCode_2'].unique()\n",
    "df = df[df.Units1>0]\n",
    "print(\"Number of residential properties with at least 1 unit: %d\" %df.AIN.shape[0])\n",
    "print(\"Number of residential units in LA County with at least 1 unit: %d\" %df.Units1.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create full mail addresses\n",
    "df.loc[:,'fullmailaddr'] = df.MailAddress.str.strip().str.replace(\"  \",\" \") +\", \"+df.MailCity.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Between Owners and Addresses\n",
    "\n",
    "Do addresses uniquely map to owners? The answer is **no**. A PO Box in Shermak Oaks had 412 names associated with it if we count properties with 0 units. An address in Arcadia has 119 names associated with it if we don't count properties with 0 units. \n",
    "\n",
    "What about the other way around, do Owner names uniquely identify addresses? LA City's properties are registered at 47 different addresses. Talking about bureaucracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique owners according to addresses: 1683277\n",
      "Number of unique owners: 1731877\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique owners according to addresses: %d\" %len(df.fullmailaddr.unique()))\n",
    "print(\"Number of unique owners: %d\" %len(df.OwnerName.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "namesPerAddress = df[['fullmailaddr','OwnerName']].drop_duplicates().groupby(\"fullmailaddr\").count().sort_values('OwnerName',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OwnerName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullmailaddr</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>610 N SANTA ANITA AVE, ARCADIA CA</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8383 WILSHIRE BLVD  STE 400, BEVERLY HILLS CA</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016 RIVERSIDE DR, LOS ANGELES CA</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PO BOX 48528, LOS ANGELES CA</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351 W 3RD ST, LOS ANGELES CA</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               OwnerName\n",
       "fullmailaddr                                            \n",
       "610 N SANTA ANITA AVE, ARCADIA CA                    119\n",
       "8383 WILSHIRE BLVD  STE 400, BEVERLY HILLS CA        107\n",
       "2016 RIVERSIDE DR, LOS ANGELES CA                    100\n",
       "PO BOX 48528, LOS ANGELES CA                          97\n",
       "2351 W 3RD ST, LOS ANGELES CA                         95"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namesPerAddress.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names associated with the Arcadia address:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "660             YALAMANCHILIRAO R\n",
       "21136    PI PROPERTIES NO 128 LLC\n",
       "26046     PI PROPERTIES NO 79 LLC\n",
       "35127       PI PROPERTIES 118 LLC\n",
       "40468          PI CONDOMINIUMS LP\n",
       "Name: OwnerName, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Names associated with the Arcadia address:\")\n",
    "df.loc[df.fullmailaddr=='610 N SANTA ANITA AVE, ARCADIA CA','OwnerName'].drop_duplicates().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "addrPerName = df[['fullmailaddr','OwnerName']].drop_duplicates().groupby(\"OwnerName\").count().sort_values('fullmailaddr',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullmailaddr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnerName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L A CITY</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GONZALEZJOSE</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EQUITY TRUST COMPANY CSTDN</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GARCIAMARIA</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GONZALEZJOSE A</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            fullmailaddr\n",
       "OwnerName                               \n",
       "L A CITY                              47\n",
       "GONZALEZJOSE                          45\n",
       "EQUITY TRUST COMPANY CSTDN            44\n",
       "GARCIAMARIA                           42\n",
       "GONZALEZJOSE A                        38"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addrPerName.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addresses associated with LA City:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "480             111 E 1ST ST  STE 212, LOS ANGELES CA\n",
       "849       6053 W CENTURY BLVD  4TH FL, LOS ANGELES CA\n",
       "1894              1 WORLD WAY  8TH FL, LOS ANGELES CA\n",
       "97849                   314 VIEWLAND PL, SAN PEDRO CA\n",
       "299961            425 S PALOS VERDES ST, SAN PEDRO CA\n",
       "345969         200 N MAIN ST  RM 1330, LOS ANGELES CA\n",
       "349763    425 S PALOS VERDES ST  5  FLR, SAN PEDRO CA\n",
       "354635                     424 W 7TH ST, SAN PEDRO CA\n",
       "413818          1200 W 7TH ST  6TH FL, LOS ANGELES CA\n",
       "443390           111 E 1ST ST  RM 213, LOS ANGELES CA\n",
       "Name: fullmailaddr, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Addresses associated with LA City:\")\n",
    "df.loc[df.OwnerName == 'L A CITY', 'fullmailaddr'].drop_duplicates().head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## County level HHI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the county level, the housing market looks virtually perfectly competitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntylvl = df.loc[:,['Units1','fullmailaddr']].groupby('fullmailaddr').sum()\n",
    "cntylvl.loc[:,'share'] = (cntylvl.Units1/cntylvl.Units1.sum()).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest property holders in LA County by owner address:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Units1</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullmailaddr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016 RIVERSIDE DR, LOS ANGELES CA</th>\n",
       "      <td>7326</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PO BOX 87407, CHICAGO IL</th>\n",
       "      <td>7254</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PO BOX 59365, SCHAUMBURG IL</th>\n",
       "      <td>6516</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9441 WILSHIRE BLVD  # PH, BEVERLY HILLS CA</th>\n",
       "      <td>6452</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150 OVERLAND AVE, CULVER CITY CA</th>\n",
       "      <td>5296</td>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Units1   share\n",
       "fullmailaddr                                              \n",
       "2016 RIVERSIDE DR, LOS ANGELES CA             7326  0.0024\n",
       "PO BOX 87407, CHICAGO IL                      7254  0.0024\n",
       "PO BOX 59365, SCHAUMBURG IL                   6516  0.0021\n",
       "9441 WILSHIRE BLVD  # PH, BEVERLY HILLS CA    6452  0.0021\n",
       "5150 OVERLAND AVE, CULVER CITY CA             5296  0.0017"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Largest property holders in LA County by owner address:\")\n",
    "cntylvl.sort_values('Units1',ascending=False).iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "County level HHI 0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"County level HHI %.3f\" %np.sum(np.square(cntylvl.share)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City Level HHI\n",
    "\n",
    "Alas, the city level proves rather bad mostly because entries for the location of the property contain countless typographical errors. In fact, if we treat unique entries for the SituCity as the number of cities in LA County then there are 637 cities, including famous locations such as CALABASSAS, RLLNG HLS, LOS ANGELESA, and the ever-a-desired-destination AGUA DUICE. \n",
    "\n",
    "I could hire someone do correct the misspellings but it probably isn't worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharesDict = {}\n",
    "hhiDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl = 'SitusCity'\n",
    "sharesDict[lvl] = df.loc[:,['Units1','fullmailaddr',lvl]].groupby([lvl,'fullmailaddr']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hhiDict[lvl] = np.square(np.divide(sharesDict[lvl].Units1,sharesDict[lvl].groupby(lvl).transform('sum').Units1)).groupby(lvl).sum()\n",
    "hhiDict[lvl].name = 'HHI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SitusCity\n",
       "LOS ANGELES       0.000171\n",
       "PASADENA          0.000564\n",
       "CULVER CITY       0.000415\n",
       "SANTA MONICA      0.001341\n",
       "WEST HOLLYWOOD    0.001948\n",
       "WRIGHTWOOD        0.011529\n",
       "Name: HHI, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select cities:\n",
    "cities = ['LOS ANGELES','PASADENA' ,'CULVER CITY', 'SANTA MONICA','WEST HOLLYWOOD','WRIGHTWOOD']\n",
    "hhiDict[lvl][cities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tract and Block Level HHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'tractGEOID'] = '06'+df.COUNTYFP10+df.TRACTCE10\n",
    "sub = df.loc[(df.UseCode_2 > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = ['tractGEOID', 'GEOID10']\n",
    "for lvl in levels:\n",
    "    sharesDict[lvl] = df.loc[:,['Units1','fullmailaddr',lvl]].groupby([lvl,'fullmailaddr']).sum()\n",
    "    hhiDict[lvl] = pd.DataFrame(np.square(np.divide(sharesDict[lvl].Units1,sharesDict[lvl].groupby(lvl).transform('sum').Units1)).groupby(lvl).sum())\n",
    "    \n",
    "    sharesDict[lvl] = sub.loc[:,['Units1','fullmailaddr',lvl]].groupby([lvl,'fullmailaddr']).sum()\n",
    "    hhiDict[lvl].loc[:,'income'] = np.square(np.divide(sharesDict[lvl].Units1,sharesDict[lvl].groupby(lvl).transform('sum').Units1)).groupby(lvl).sum()\n",
    "    \n",
    "    hhiDict[lvl].columns = ['allProperties','incomeProperties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Tract and Block results to CSVs\n",
    "hhiDict['tractGEOID'].to_csv(\"/\".join([data_path, 'tractHHI_LA.csv']), header=True)\n",
    "hhiDict['GEOID10'].to_csv(\"/\".join([data_path, 'blockHHI_LA.csv']),header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
